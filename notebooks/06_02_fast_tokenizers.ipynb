{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "764cef44-5fb8-4d1c-89ce-c785b92b48f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d1300bb-84f3-4cbc-a51b-395387ccaf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"bert-base-cased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e572d999-1469-4ebb-b4cd-fbb5a1575494",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "270f78ec-0a96-4f46-96d3-0f373a8fcf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "example = \"My name is Sylvain and I work at Hugging Face in Brooklyn.\"\n",
    "encoding = tokenizer(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6768885-bd5b-4123-a782-6baa197f6c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    }
   ],
   "source": [
    "print(type(encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3607db8-43d6-42d1-95fa-fc03e5b1d53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "128d7699-103b-4712-8f0a-4c4b503814f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da22fad6-1691-4d9d-b8cf-85b44e1b0d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'My',\n",
       " 'name',\n",
       " 'is',\n",
       " 'S',\n",
       " '##yl',\n",
       " '##va',\n",
       " '##in',\n",
       " 'and',\n",
       " 'I',\n",
       " 'work',\n",
       " 'at',\n",
       " 'Hu',\n",
       " '##gging',\n",
       " 'Face',\n",
       " 'in',\n",
       " 'Brooklyn',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee4e19ec-aeaf-4ba6-a608-a2941b281ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 3, 3, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b6e0e4f-7f7f-48eb-b00c-4b189ebd8783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>name</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>##yl</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>##va</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>##in</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>work</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>at</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hu</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>##gging</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Face</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>in</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>.</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[SEP]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token    id\n",
       "0      [CLS]   NaN\n",
       "1         My   0.0\n",
       "2       name   1.0\n",
       "3         is   2.0\n",
       "4          S   3.0\n",
       "5       ##yl   3.0\n",
       "6       ##va   3.0\n",
       "7       ##in   3.0\n",
       "8        and   4.0\n",
       "9          I   5.0\n",
       "10      work   6.0\n",
       "11        at   7.0\n",
       "12        Hu   8.0\n",
       "13   ##gging   8.0\n",
       "14      Face   9.0\n",
       "15        in  10.0\n",
       "16  Brooklyn  11.0\n",
       "17         .  12.0\n",
       "18     [SEP]   NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"token\": encoding.tokens(), \"id\": encoding.word_ids()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f541124a-c7b0-46cd-805d-617089111d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba3bf232225497791c86af81e3fd291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75289d87d1ff43219282816145bbb26e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c454f884b5642fcae1f39a56f53c348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed29f6fa92c4a8fbad6ea961a2c284e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer1 = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d511c8c-1a12-4df6-9f11-8057bc4b433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding1 = tokenizer1(\"81s\")\n",
    "encoding2 = tokenizer2(\"81s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f6f084e-7e26-4db0-a72d-f31b49ed3632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '81', '##s', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(encoding1.tokens())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1afef5b5-aa78-48de-841a-a54461d17900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '81', 's', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(encoding2.tokens())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c071dcca-1f16-48b4-8782-864af67b56b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sylvain'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start, end = encoding.word_to_chars(3)\n",
    "example[start: end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa0bfd72-f2a3-432e-bf1b-9fb740af72a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer([\"Sentence 1.\", \"Sentence 2.\", \"Sentence 3.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35662b12-e721-4b94-9436-4ead29dbef13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 14895, 5208, 2093, 122, 119, 102], [101, 14895, 5208, 2093, 123, 119, 102], [101, 14895, 5208, 2093, 124, 119, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0667b903-b327-470a-ab3a-f3b218eddfc1",
   "metadata": {},
   "source": [
    "# Token classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f42a463e-2559-46ae-ab35-fc6f44a1e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"dbmdz/bert-large-cased-finetuned-conll03-english\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e3a02be-918d-4dfe-8acf-63fb2f71b77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "token_classifier = pipeline(\"token-classification\", model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee1eabb4-92df-4a5e-9cb5-963070b59b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"My name is Sylvain and I work at Hugging Face in Brooklyn.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7489a2-4e7e-401e-8637-6ce67e60c9e3",
   "metadata": {},
   "source": [
    "## Token-level classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5b46a208-de94-4a92-b57b-ec25ec7c8276",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = token_classifier(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8e8bd7ac-9d6b-4ecb-8115-9b25507d442e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'I-PER',\n",
       "  'score': 0.99938285,\n",
       "  'index': 4,\n",
       "  'word': 'S',\n",
       "  'start': 11,\n",
       "  'end': 12},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99815494,\n",
       "  'index': 5,\n",
       "  'word': '##yl',\n",
       "  'start': 12,\n",
       "  'end': 14},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99590707,\n",
       "  'index': 6,\n",
       "  'word': '##va',\n",
       "  'start': 14,\n",
       "  'end': 16},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99923277,\n",
       "  'index': 7,\n",
       "  'word': '##in',\n",
       "  'start': 16,\n",
       "  'end': 18},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9738931,\n",
       "  'index': 12,\n",
       "  'word': 'Hu',\n",
       "  'start': 33,\n",
       "  'end': 35},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.976115,\n",
       "  'index': 13,\n",
       "  'word': '##gging',\n",
       "  'start': 35,\n",
       "  'end': 40},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9887976,\n",
       "  'index': 14,\n",
       "  'word': 'Face',\n",
       "  'start': 41,\n",
       "  'end': 45},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9932106,\n",
       "  'index': 16,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da207813-c364-4c75-bf7b-85109abffe86",
   "metadata": {},
   "source": [
    "## Grouping of classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "51d389e0-13c7-4b41-bf1a-027847321757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "token_grouped_classifier = pipeline(\"token-classification\", aggregation_strategy=\"simple\", model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "062f0f79-8ee5-4569-8606-2134e47298b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = token_grouped_classifier(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "aa0785a3-3e54-4ec0-928e-5eefe1809eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9981694,\n",
       "  'word': 'Sylvain',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9796019,\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 33,\n",
       "  'end': 45},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9932106,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd545876-ea34-4efc-98d6-2d157a1da9c8",
   "metadata": {},
   "source": [
    "# Without pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "37e04ad4-2bd5-47e7-9b09-36b58ce0d8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForTokenClassification.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6de27d71-e7d5-43a9-9d8d-b73d2407f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(example, return_tensors=\"pt\", return_offsets_mapping=True)\n",
    "outputs = model(\n",
    "    input_ids=inputs.input_ids,\n",
    "    token_type_ids=inputs.token_type_ids,\n",
    "    attention_mask=inputs.attention_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "feb04b9a-1b02-4b6f-a130-9ca20694950c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 19])\n",
      "torch.Size([1, 19, 9])\n"
     ]
    }
   ],
   "source": [
    "print(inputs[\"input_ids\"].shape)\n",
    "print(outputs[\"logits\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "63ebec1b-2715-4dc2-8523-43f9ee7862ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = F.softmax(outputs[\"logits\"], dim=-1).squeeze(0).tolist()\n",
    "preds = outputs[\"logits\"].argmax(dim=-1).squeeze(0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2ce7ebd8-936e-4c40-9260-419d1fcdf2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 4, 4, 4, 4, 0, 0, 0, 0, 6, 6, 6, 0, 8, 0, 0]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f0ca94-a2c2-46e3-9d5b-91706391f2f9",
   "metadata": {},
   "source": [
    "## Label definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "fc3babeb-3236-4e3c-892e-138236157c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-MISC',\n",
       " 2: 'I-MISC',\n",
       " 3: 'B-PER',\n",
       " 4: 'I-PER',\n",
       " 5: 'B-ORG',\n",
       " 6: 'I-ORG',\n",
       " 7: 'B-LOC',\n",
       " 8: 'I-LOC'}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe18717-67dd-4380-94b2-dd322e7e2912",
   "metadata": {},
   "source": [
    "## Aggregate token predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "fbd38fdf-c7d8-4bb3-86d1-5a8c0185c652",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "tokens = inputs.tokens()\n",
    "\n",
    "for idx, pred in enumerate(preds):\n",
    "    label = model.config.id2label[pred]\n",
    "    if label != \"O\":\n",
    "        results.append(\n",
    "            {\"entity\": label, \"score\": probs[idx][pred], \"word\": tokens[idx]}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c7a75f45-5eee-44fb-bbf8-6319e034ff3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'I-PER', 'score': 0.9993828535079956, 'word': 'S'},\n",
       " {'entity': 'I-PER', 'score': 0.9981548190116882, 'word': '##yl'},\n",
       " {'entity': 'I-PER', 'score': 0.995907187461853, 'word': '##va'},\n",
       " {'entity': 'I-PER', 'score': 0.9992327690124512, 'word': '##in'},\n",
       " {'entity': 'I-ORG', 'score': 0.9738931059837341, 'word': 'Hu'},\n",
       " {'entity': 'I-ORG', 'score': 0.9761149883270264, 'word': '##gging'},\n",
       " {'entity': 'I-ORG', 'score': 0.9887974858283997, 'word': 'Face'},\n",
       " {'entity': 'I-LOC', 'score': 0.99321049451828, 'word': 'Brooklyn'}]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "54470100-fcbc-4c69-8e54-face189f06db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text span for each token, without the extra characters (\"##\")\n",
    "offsets = inputs.offset_mapping.squeeze(0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "398a0cb5-9eed-4f1d-8c5b-1a750f4a21c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "My\n",
      "name\n",
      "is\n",
      "S\n",
      "yl\n",
      "va\n",
      "in\n",
      "and\n",
      "I\n",
      "work\n",
      "at\n",
      "Hu\n",
      "gging\n",
      "Face\n",
      "in\n",
      "Brooklyn\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, offset in enumerate(offsets):\n",
    "    print(example[offset[0]: offset[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f7a8eb-2c72-4fde-a7df-6f4a80319a0f",
   "metadata": {},
   "source": [
    "## Fully recreate pipeline results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "aa9500a1-32f0-412f-be90-ebda1e5e0346",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "tokens = inputs.tokens()\n",
    "offsets = inputs.offset_mapping.squeeze(0).tolist()\n",
    "\n",
    "for idx, pred in enumerate(preds):\n",
    "    label = model.config.id2label[pred]\n",
    "    if label != \"O\":\n",
    "        start, end = offsets[idx]\n",
    "        results.append({\n",
    "            \"entity\": label,\n",
    "            \"score\": probs[idx][pred],\n",
    "            \"word\": tokens[idx],\n",
    "            \"start\": start,\n",
    "            \"end\": end,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d6e04036-de6b-420b-9a24-826518166a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'I-PER',\n",
       "  'score': 0.9993828535079956,\n",
       "  'word': 'S',\n",
       "  'start': 11,\n",
       "  'end': 12},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9981548190116882,\n",
       "  'word': '##yl',\n",
       "  'start': 12,\n",
       "  'end': 14},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.995907187461853,\n",
       "  'word': '##va',\n",
       "  'start': 14,\n",
       "  'end': 16},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9992327690124512,\n",
       "  'word': '##in',\n",
       "  'start': 16,\n",
       "  'end': 18},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9738931059837341,\n",
       "  'word': 'Hu',\n",
       "  'start': 33,\n",
       "  'end': 35},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9761149883270264,\n",
       "  'word': '##gging',\n",
       "  'start': 35,\n",
       "  'end': 40},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9887974858283997,\n",
       "  'word': 'Face',\n",
       "  'start': 41,\n",
       "  'end': 45},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.99321049451828,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3b6137-f153-49aa-a0bb-8e8d8c31ce2c",
   "metadata": {},
   "source": [
    "## Fully recreate pipeline results with grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d8e96c0c-a089-482b-9007-796cb3b89b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "idx = 0\n",
    "while idx < len(preds):\n",
    "    pred = preds[idx]\n",
    "    label = model.config.id2label[pred]\n",
    "    if label != \"O\":\n",
    "        # Remove B- or I-\n",
    "        label = label[2:]\n",
    "        start, _ = offsets[idx]\n",
    "\n",
    "        # Get all tokens with I-label\n",
    "        all_scores = []\n",
    "        while(idx < len(preds) and model.config.id2label[preds[idx]] == f\"I-{label}\"):\n",
    "            all_scores.append(probs[idx][pred])\n",
    "            _, end = offsets[idx]\n",
    "            idx += 1\n",
    "\n",
    "        # Set score as mean of all scores for tokens in grouped entity\n",
    "        score = np.mean(all_scores).item()\n",
    "        word = example[start: end]\n",
    "        results.append({\n",
    "            \"entity_group\": label,\n",
    "            \"score\": score,\n",
    "            \"word\": word,\n",
    "            \"start\": start,\n",
    "            \"end\": end,\n",
    "        })\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "b0c34856-696a-4d6d-b3fd-fa4df9ea65fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.998169407248497,\n",
       "  'word': 'Sylvain',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9796018600463867,\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 33,\n",
       "  'end': 45},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.99321049451828,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
