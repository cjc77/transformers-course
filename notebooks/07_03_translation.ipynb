{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "902160df-d077-46ad-a8c5-093f8ffe9703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import multiprocessing\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import evaluate\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    get_scheduler\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d5fbdd-451b-4eee-a16e-5c5ca54dcf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores_avail = max(1, multiprocessing.cpu_count() - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dd0635-0ca7-4184-b600-2c34a7763264",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9489deb-ec21-4960-a3ee-141d1e40db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_checkpoint = \"kde4\"\n",
    "dataset_commit_id = \"12cd06d961fae220f6ef1ab533321b8e9ddc3533\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7de6f088-6ea2-4f88-88d1-07ff9cd7833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = load_dataset(dataset_checkpoint, lang1=\"en\", lang2=\"fr\", revision=dataset_commit_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf0751e4-268c-4490-9a2f-c7cca2384628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 210173\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe6db5b-4c0b-4064-969d-edd5abc37693",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e9d300e-bc30-4912-9725-243fa60120a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_datasets = raw_datasets[\"train\"].train_test_split(train_size=0.9, seed=20)\n",
    "split_datasets[\"validation\"] = split_datasets.pop(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7398f037-331f-4b05-a474-c5e38ef9a801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 189155\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 21018\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd479194-26bf-4fce-b1c8-2853d909d3b6",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24bbd0ae-0d90-4b28-ba08-35a29b51dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "model_commit_id = \"0b11e64c9efac19014daf61fb333354e09000f00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "213c59dc-a495-4d77-b0ad-16d07da39827",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = pipeline(\"translation\", model=model_checkpoint, revision=model_commit_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6fa2db-52dc-4132-b4c5-42292196ecd9",
   "metadata": {},
   "source": [
    "## Translation differences\n",
    "The pre-trained model tends to use less formal translations (e.g., keeps certain english terms in the translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16bbfd8d-473a-479e-8446-190ef8babe14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Default to expanded threads',\n",
       " 'fr': 'Par défaut, développer les fils de discussion'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_datasets[\"train\"][1][\"translation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cc9b833-ed20-494c-85aa-0e4e4fa1f376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Par défaut pour les threads élargis'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(split_datasets[\"train\"][1][\"translation\"][\"en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "001b4d75-e641-4fa4-95a1-12e1b887bd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Unable to import %1 using the OFX importer plugin. This file is not the correct format.',\n",
       " 'fr': \"Impossible d'importer %1 en utilisant le module d'extension d'importation OFX. Ce fichier n'a pas un format correct.\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_datasets[\"train\"][172][\"translation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c61a3174-3aed-4b75-9784-5016bc06f4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': \"Impossible d'importer %1 en utilisant le plugin d'importateur OFX. Ce fichier n'est pas le bon format.\"}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(split_datasets[\"train\"][172][\"translation\"][\"en\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5bd367-857d-44cf-9667-0cdf3f90f213",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d79ec31-0705-4186-b9f5-9c4a24b1de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, revision=model_commit_id, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cc2f2bb-9af1-459b-ab42-7e6c13ff50a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sentence = split_datasets[\"train\"][1][\"translation\"][\"en\"]\n",
    "fr_sentence = split_datasets[\"train\"][1][\"translation\"][\"fr\"]\n",
    "inputs = tokenizer(en_sentence, text_target=fr_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1da844b-a702-45cf-bbc4-87029ee5e916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [47591, 12, 9842, 19634, 9, 0], 'attention_mask': [1, 1, 1, 1, 1, 1], 'labels': [577, 5891, 2, 3184, 16, 2542, 5, 1710, 0]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fc576dd-65ca-4285-9f06-714366584b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Par', '▁défaut', ',', '▁développer', '▁les', '▁fils', '▁de', '▁discussion', '</s>']\n",
      "['▁Par', '▁dé', 'f', 'aut', ',', '▁dé', 've', 'lop', 'per', '▁les', '▁fil', 's', '▁de', '▁discussion', '</s>']\n"
     ]
    }
   ],
   "source": [
    "wrong_targets = tokenizer(fr_sentence)\n",
    "print(tokenizer.convert_ids_to_tokens(inputs[\"labels\"]))\n",
    "print(tokenizer.convert_ids_to_tokens(wrong_targets[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7da44071-638f-4ef5-a690-6d0eb52c57a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2da9f9bf-ec76-4299-adcb-919e1fff17ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [ex[\"en\"] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[\"fr\"] for ex in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, text_target=targets, max_length=max_length, truncation=True\n",
    "    )\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b76a54f1-fa8d-470c-815b-9d98b876cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = split_datasets.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=split_datasets[\"train\"].column_names,\n",
    "    num_proc=num_cores_avail\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b108905-c41b-4ad5-a582-87fc185abb00",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb70262e-1c8b-4e01-bc6d-a3f139501b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint, revision=model_commit_id)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72aa2a74-709f-46ab-a410-197d12f45176",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(1, 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb59d7c2-912a-4495-9ac5-434153c9e758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd2c3dea-7e6f-4c84-ab57-4a7751f05f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  577,  5891,     2,  3184,    16,  2542,     5,  1710,     0,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100],\n",
       "        [ 1211,     3,    49,  9409,  1211,     3, 29140,   817,  3124,   817,\n",
       "           550,  7032,  5821,  7907, 12649,     0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for appropriate padding of labels\n",
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c6d366c-d958-4428-a51e-6134cbef298f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[59513,   577,  5891,     2,  3184,    16,  2542,     5,  1710,     0,\n",
       "         59513, 59513, 59513, 59513, 59513, 59513],\n",
       "        [59513,  1211,     3,    49,  9409,  1211,     3, 29140,   817,  3124,\n",
       "           817,   550,  7032,  5821,  7907, 12649]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These should be right-shifted versions of the labels\n",
    "batch[\"decoder_input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc85d3ac-9cd6-4653-a91d-576ed586c09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[577, 5891, 2, 3184, 16, 2542, 5, 1710, 0]\n",
      "[1211, 3, 49, 9409, 1211, 3, 29140, 817, 3124, 817, 550, 7032, 5821, 7907, 12649, 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 3):\n",
    "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc41806-be97-4543-b5a2-9bcf6f9944c0",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9380f2ce-6170-4827-893e-a9a83b1f4cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "481fc9d3-c0ff-4b25-ae27-1b36de38da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [\n",
    "    \"This plugin lets you translate web pages between several languages automatically.\"\n",
    "]\n",
    "references = [\n",
    "    [\n",
    "        \"This plugin allows you to automatically translate web pages between several languages.\"\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b3b626b-aa28-467a-a5d8-72e8d535aa33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 46.750469682990165,\n",
       " 'counts': [11, 6, 4, 3],\n",
       " 'totals': [12, 11, 10, 9],\n",
       " 'precisions': [91.66666666666667,\n",
       "  54.54545454545455,\n",
       "  40.0,\n",
       "  33.333333333333336],\n",
       " 'bp': 0.9200444146293233,\n",
       " 'sys_len': 12,\n",
       " 'ref_len': 13}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9067ef1a-0e63-4a4d-8701-835826a5e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [\"This This This This\"]\n",
    "references = [\n",
    "    [\n",
    "        \"This plugin allows you to automatically translate web pages between several languages.\"\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85dc959f-c63d-4422-a59e-67b7bfd91847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 1.683602693167689,\n",
       " 'counts': [1, 0, 0, 0],\n",
       " 'totals': [4, 3, 2, 1],\n",
       " 'precisions': [25.0, 16.666666666666668, 12.5, 12.5],\n",
       " 'bp': 0.10539922456186433,\n",
       " 'sys_len': 4,\n",
       " 'ref_len': 13}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c274d1f7-f5b0-4653-b4df-ac43da7c6953",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [\"This plugin\"]\n",
    "references = [\n",
    "    [\n",
    "        \"This plugin allows you to automatically translate web pages between several languages.\"\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58945bbc-a277-44fd-a2a9-7c4a56192f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.0,\n",
       " 'counts': [2, 1, 0, 0],\n",
       " 'totals': [2, 1, 0, 0],\n",
       " 'precisions': [100.0, 100.0, 0.0, 0.0],\n",
       " 'bp': 0.004086771438464067,\n",
       " 'sys_len': 2,\n",
       " 'ref_len': 13}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4b2e0fd-2de6-4ff1-a0b7-2c0ccd2fa15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 in labels\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    return {\"bleu\": result[\"score\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a83a0f2-bf3c-442a-9746-ba6accf003f1",
   "metadata": {},
   "source": [
    "# Model fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7dcc108a-c908-40c6-a382-88aebe001519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Helsinki-NLP/opus-mt-en-fr'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b15855c8-f4cf-4b8e-bc72-e7a9b3aa9ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Seq2SeqTrainingArguments(\n",
    "    \"../temp/07/marian-finetuned-kde4-en-to-fr\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ce3d09-ebdc-4d3e-9249-048f5058390e",
   "metadata": {},
   "source": [
    "## Train and evaluate with subsample\n",
    "Only use a subsample here, otherwise it takes too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02eddd2d-c314-436f-a054-ce53fe28ffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_samp = int(0.1 * tokenized_datasets[\"train\"].num_rows)\n",
    "n_eval_samp = int(0.1 * tokenized_datasets[\"validation\"].num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1d9340-8d0d-4bed-baaf-dfb90d5bb3e5",
   "metadata": {},
   "source": [
    "## Evaluate at start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0fdae82b-a8f9-4cf0-8049-3a8da4116553",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"].shuffle(seed=42).select(range(n_train_samp)),\n",
    "    eval_dataset=tokenized_datasets[\"validation\"].shuffle(seed=42).select(range(n_eval_samp)),\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a625956-7ff7-427a-be87-ee30c862b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(max_length=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ddd765-c461-4c1e-b34f-41630636bd2f",
   "metadata": {},
   "source": [
    "## Train (fine-tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211b8c3d-4951-4500-9c98-57bfdad43828",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3f2b0c-7541-480b-b505-b7e412836918",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(max_length=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d97ede-44ce-49ff-8e33-849be433d978",
   "metadata": {},
   "source": [
    "# Train and evaluate model with Accelerate & custom loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e4284c-38b6-4f3f-afab-723f4d3af525",
   "metadata": {},
   "source": [
    "## Dataloaders and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31e13d4e-e5bd-4e68-ae90-2abca1ab8b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"].shuffle(seed=42).select(range(n_train_samp)),\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"].shuffle(seed=42).select(range(n_eval_samp)),\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1f9e44-a27d-40ff-a4c7-74cc9554b1f0",
   "metadata": {},
   "source": [
    "### Load initial pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b927d41-cf6a-457a-91de-c36fa92893f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274c4c5c-3033-4f2f-a39f-63b8b1d96285",
   "metadata": {},
   "source": [
    "### Set up and accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e4b07fa0-43d5-400c-9402-3fc6aa70f8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b8f4318-d07e-47cc-b96f-f3f04e95197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e5ad3a0-978d-4f6a-a294-887ea4bf8759",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "27638d3b-c246-426a-9db4-720475bf0940",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "75036b9d-8508-4eb4-a24f-9b59bad7a74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../temp/07/marian-finetuned-kde4-en-to-fr-accelerate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7cf35c-865b-4519-857e-bb4ce141024f",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2c6375a5-5634-4e61-984f-303c5252833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 in labels\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Post-process\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "    return decoded_preds, decoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d8b2f9ec-fa7f-4b01-8ff3-c5b09f3b136b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf1a65972a8422a80a0d8d4806fb334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7095 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f736f9d8be5b46968b969e5705c83c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, BLEU score: 46.28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96cc06b7a90f48a28b8d1419597c76a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, BLEU score: 45.77\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ffa926ec574f3e83eda00f7440ead8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, BLEU score: 47.23\n"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Train\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    for batch in tqdm(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = accelerator.unwrap_model(model).generate(\n",
    "                batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "                max_length=128\n",
    "            )\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        # Pad predictions/labels before gathering\n",
    "        generated_tokens = accelerator.pad_across_processes(\n",
    "            generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "\n",
    "        predictions_gathered = accelerator.gather(generated_tokens)\n",
    "        labels_gathered = accelerator.gather(labels)\n",
    "\n",
    "        decoded_preds, decoded_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "        metric.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    results = metric.compute()\n",
    "    print(f\"epoch {epoch}, BLEU score: {results['score']:.2f}\")\n",
    "\n",
    "    # Save checkpoint\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf11562-1ec7-47d3-8fcf-54588ebb1abd",
   "metadata": {},
   "source": [
    "## Use fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cb407b8e-849e-4f5c-841e-86119405a45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Par défaut pour développer les fils de discussion'}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accel_local_model_checkpoint = \"../temp/07/marian-finetuned-kde4-en-to-fr-accelerate\"\n",
    "translator = pipeline(\"translation\", model=accel_local_model_checkpoint)\n",
    "translator(\"Default to expanded threads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fd1ab123-91c8-49e3-843d-f28803117c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': \"Impossible d'importer %1 en utilisant le module externe d'importation OFX. Ce fichier n'est pas le bon format.\"}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(\n",
    "    \"Unable to import %1 using the OFX importer plugin. This file is not the correct format.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
