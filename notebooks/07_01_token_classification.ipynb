{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "723f956c-303a-4607-9346-7471c9087305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    get_scheduler,\n",
    "    pipeline\n",
    ")\n",
    "from accelerate import Accelerator\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55dd3acd-be3f-4624-93ef-7cbfb440ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9425514-fba4-49cb-992c-01caa6a8f093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0083515-38fa-4173-9b36-0969de44f374",
   "metadata": {},
   "source": [
    "# Investigate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7709cc0c-ed8b-4fc7-9daf-60a6a25e5276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0][\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da5dd311-426e-4b35-8d66-d8d3335562b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0, 7, 0, 0, 0, 7, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0][\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb3f120-7a2f-4f62-95a2-df275cf62f97",
   "metadata": {},
   "source": [
    "## Label meanings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90710cf6-8e3a-434b-8415-f3f12857947f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"].features[\"ner_tags\"].feature.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d935987a-09b3-4be2-b0fe-a9e55610da53",
   "metadata": {},
   "source": [
    "## Match labels to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52f8bc8a-7be5-4187-a79f-013ba06e06c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_words_and_labels(words, labels, label_names, max_line=80):\n",
    "    line1 = \"\"\n",
    "    line2 = \"\"\n",
    "    \n",
    "    for word, label in zip(words, labels):\n",
    "        full_label = label_names[label]\n",
    "        max_length = max(len(word), len(full_label))\n",
    "        line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "        line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "        if len(line1) > max_line:\n",
    "            print(line1)\n",
    "            print(line2)\n",
    "            line1 = \"\"\n",
    "            line2 = \"\"\n",
    "    print(line1)\n",
    "    print(line2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759a4bfe-b788-4b62-b035-9157305d2ec6",
   "metadata": {},
   "source": [
    "### NER labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "893b5afe-7ac2-4d12-9427-18161db9bd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU    rejects German call to boycott British lamb . \n",
      "B-ORG O       B-MISC O    O  O       B-MISC  O    O \n"
     ]
    }
   ],
   "source": [
    "pp_words_and_labels(\n",
    "    words=raw_datasets[\"train\"][0][\"tokens\"],\n",
    "    labels=raw_datasets[\"train\"][0][\"ner_tags\"],\n",
    "    label_names=raw_datasets[\"train\"].features[\"ner_tags\"].feature.names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de069f0a-c372-4b15-939d-aca28e0859a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Germany 's representative to the European Union 's veterinary committee Werner Zwingmann said on Wednesday consumers \n",
      "B-LOC   O  O              O  O   B-ORG    I-ORG O  O          O         B-PER  I-PER     O    O  O         O         \n",
      "should buy sheepmeat from countries other than Britain until the scientific advice was clearer . \n",
      "O      O   O         O    O         O     O    B-LOC   O     O   O          O      O   O       O \n"
     ]
    }
   ],
   "source": [
    "pp_words_and_labels(\n",
    "    words=raw_datasets[\"train\"][4][\"tokens\"],\n",
    "    labels=raw_datasets[\"train\"][4][\"ner_tags\"],\n",
    "    label_names=raw_datasets[\"train\"].features[\"ner_tags\"].feature.names,\n",
    "    max_line=110\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce96d13-7184-4330-8d14-90b41336cb22",
   "metadata": {},
   "source": [
    "### POS labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e249c5d2-828b-4537-8152-4ac694c72b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU  rejects German call to boycott British lamb . \n",
      "NNP VBZ     JJ     NN   TO VB      JJ      NN   . \n"
     ]
    }
   ],
   "source": [
    "pp_words_and_labels(\n",
    "    raw_datasets[\"train\"][0][\"tokens\"],\n",
    "    raw_datasets[\"train\"][0][\"pos_tags\"],\n",
    "    raw_datasets[\"train\"].features[\"pos_tags\"].feature.names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d121c535-3b95-4211-859e-833d13627255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Germany 's  representative to the European Union 's  veterinary committee Werner Zwingmann said on Wednesday consumers \n",
      "NNP     POS NN             TO DT  NNP      NNP   POS JJ         NN        NNP    NNP       VBD  IN NNP       NNS       \n",
      "should buy sheepmeat from countries other than Britain until the scientific advice was clearer . \n",
      "MD     VB  NN        IN   NNS       JJ    IN   NNP     IN    DT  JJ         NN     VBD JJR     . \n"
     ]
    }
   ],
   "source": [
    "pp_words_and_labels(\n",
    "    raw_datasets[\"train\"][4][\"tokens\"],\n",
    "    raw_datasets[\"train\"][4][\"pos_tags\"],\n",
    "    raw_datasets[\"train\"].features[\"pos_tags\"].feature.names,\n",
    "    max_line=110\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618ea266-d6a8-4865-a2b9-17a6f7519433",
   "metadata": {},
   "source": [
    "### Chunking labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b75a8f0-c5c8-4cdb-be97-7dfdf2b7bfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU   rejects German call to   boycott British lamb . \n",
      "B-NP B-VP    B-NP   I-NP B-VP I-VP    B-NP    I-NP O \n"
     ]
    }
   ],
   "source": [
    "pp_words_and_labels(\n",
    "    raw_datasets[\"train\"][0][\"tokens\"],\n",
    "    raw_datasets[\"train\"][0][\"chunk_tags\"],\n",
    "    raw_datasets[\"train\"].features[\"chunk_tags\"].feature.names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4302c8b-ddb7-4a67-aba6-fd002c29fcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Germany 's   representative to   the  European Union 's   veterinary committee Werner Zwingmann said on   Wednesday \n",
      "B-NP    B-NP I-NP           B-PP B-NP I-NP     I-NP  B-NP I-NP       I-NP      I-NP   I-NP      B-VP B-PP B-NP      \n",
      "consumers should buy  sheepmeat from countries other  than Britain until  the  scientific advice was  clearer . \n",
      "I-NP      B-VP   I-VP B-NP      B-PP B-NP      B-ADJP B-PP B-NP    B-SBAR B-NP I-NP       I-NP   B-VP B-ADJP  O \n"
     ]
    }
   ],
   "source": [
    "pp_words_and_labels(\n",
    "    raw_datasets[\"train\"][4][\"tokens\"],\n",
    "    raw_datasets[\"train\"][4][\"chunk_tags\"],\n",
    "    raw_datasets[\"train\"].features[\"chunk_tags\"].feature.names,\n",
    "    max_line=115\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df3c72a-877b-4082-90d7-7c71d34fd6e7",
   "metadata": {},
   "source": [
    "# Define tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "750fc531-3e92-4489-adeb-7c26a89d8510",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"bert-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50eb2a3a-e803-4564-af6f-beac1ffc5bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06f8f574-60fd-4eac-b25c-d3b877eb638e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1246b6df-529f-4e9e-a8af-57714cdd2c60",
   "metadata": {},
   "source": [
    "## Text is pre-tokenized, need to tell our tokenizer to handle this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a0491fe-dd6f-40f1-98a2-9f21afcb6d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a8d28b3-3e19-4db7-a51b-2622050a405a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'EU',\n",
       " 'rejects',\n",
       " 'German',\n",
       " 'call',\n",
       " 'to',\n",
       " 'boycott',\n",
       " 'British',\n",
       " 'la',\n",
       " '##mb',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "848f06c9-8cba-4a31-9650-ef49751ddaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288c3f57-0889-4139-9df2-7ff5b4f6554c",
   "metadata": {},
   "source": [
    "### Label and token mismatch\n",
    "\n",
    "Length of labels & tokens no longer match, since words were split up and special tokens were added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aecc657b-a440-44af-998d-e4ea1ed1912d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 12\n"
     ]
    }
   ],
   "source": [
    "print(len(labels), len(inputs.tokens()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99b06d9-27c0-45ea-b6f4-3302e5260a22",
   "metadata": {},
   "source": [
    "### Solution\n",
    "Match tokens to corresponding word and then expanding the label list to match the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "583c9ee0-625e-4c23-9464-7c776f0a3433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47b28737-9940-49c8-9ce0-59bd801b242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If label is B-XXX, change it to I-XXX since we're continuing the same word\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bc98710-560e-4550-9090-e65a573af69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "word_ids = inputs.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2419a11c-72de-4aa8-a0ce-e05cf257dd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 7, 0, 0, 0, 7, 0, 0]\n",
      "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "print(align_labels_with_tokens(labels, word_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec950b30-fdba-4bbb-95ee-500dc7941281",
   "metadata": {},
   "source": [
    "# Tokenize\n",
    "Tokenize while aligning labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70167ffb-34af-4644-999a-9e5ebc974a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80063b60-28d0-4ed9-8b96-bcbdb44434e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580d987aa1104c4b84165decf12d1b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f867f5d1-539c-420d-9fd3-6b593763cd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101,\n",
       "  7270,\n",
       "  22961,\n",
       "  1528,\n",
       "  1840,\n",
       "  1106,\n",
       "  21423,\n",
       "  1418,\n",
       "  2495,\n",
       "  12913,\n",
       "  119,\n",
       "  102],\n",
       " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'labels': [-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96f6d41-6d77-4d72-8cd8-a9c692e61139",
   "metadata": {},
   "source": [
    "# Model fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab0f92a-1b6d-4a8c-a7fc-c95b96fcd481",
   "metadata": {},
   "source": [
    "## Data collation\n",
    "Need to pad both inputs and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e286c055-f663-4d4c-8701-84948119a5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "114947e1-a950-4337-af1d-21b08dbebf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e462244c-8a47-4e96-966f-2278b477637e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  7270, 22961,  1528,  1840,  1106, 21423,  1418,  2495, 12913,\n",
       "           119,   102],\n",
       "        [  101,  1943, 14428,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],\n",
       "        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04be64d1-1b1b-4f81-94bb-1ac278238a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] EU rejects German call to boycott British lamb. [SEP]',\n",
       " '[CLS] Peter Blackburn [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(ids) for ids in batch.input_ids.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b0a6d43-88df-455c-8600-7fa41840715a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],\n",
       "        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70c82cb7-db33-453a-8373-454d0a525029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n",
      "[-100, 1, 2, -100]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59f2625-246b-48bc-8aa4-ce0176e25a7d",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d987cac2-c49b-4205-9197-2360cad4e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9968f4cc-761e-49b3-94a2-9a534223ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "label_names = raw_datasets[\"train\"].features[\"ner_tags\"].feature.names\n",
    "labels = [label_names[i] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b082a66-3bb9-4526-98d1-08359e382e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f79bbe66-2613-42c4-ba0a-3d16d03abacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some fake predictions to look at metrics\n",
    "predictions = labels.copy()\n",
    "predictions[2] = \"O\"\n",
    "predictions[-2] = \"I-MISC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af13ead8-4b15-4421-b5b3-6a2e1ac1b907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ORG', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O']\n",
      "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "print(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c9b2f58-c7c1-432c-a617-ff9ea0dffcea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MISC': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2},\n",
       " 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'overall_precision': 0.5,\n",
       " 'overall_recall': 0.3333333333333333,\n",
       " 'overall_f1': 0.4,\n",
       " 'overall_accuracy': 0.7777777777777778}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=[predictions], references=[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54e5f080-4f11-4467-a586-fbc7618dfd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepped_labels_and_preds(labels, predictions, label_names):\n",
    "    # Remove masked indices and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return true_labels, true_predictions\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    true_labels, true_predictions = prepped_labels_and_preds(labels, predictions, label_names)\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56125f0-d274-4b35-80e9-d46e76cfca32",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83a18e78-8803-42e9-adf3-a48ec9f78e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be05bf77-9d53-4f49-80cc-4b2e43428068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-PER',\n",
       " 2: 'I-PER',\n",
       " 3: 'B-ORG',\n",
       " 4: 'I-ORG',\n",
       " 5: 'B-LOC',\n",
       " 6: 'I-LOC',\n",
       " 7: 'B-MISC',\n",
       " 8: 'I-MISC'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cdf41de1-a604-470b-b23e-cebe10017b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ab6f9a55-2fa2-452f-be32-274deeae2088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e4cabca-e098-4963-b441-a72564b484d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"../temp/07/bert-finetuned-ner\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    overwrite_output_dir=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e655fc2-d56a-44a6-aacc-d0b0cbac5b71",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a194b9a3-0c41-4fa7-8db4-d7c660549335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training on 25% of the data to save time\n",
    "n_train_use = int(0.25 * tokenized_datasets[\"train\"].num_rows)\n",
    "n_eval_use = int(0.25 * tokenized_datasets[\"validation\"].num_rows)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"].shuffle(seed=42).select(range(n_train_use)),\n",
    "    eval_dataset=tokenized_datasets[\"validation\"].shuffle(seed=42).select(range(n_eval_use)),\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0366c463-93ea-4a93-9f16-408668c12eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carcook/dev/transformers-course/myenv/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1317' max='1317' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1317/1317 02:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.100703</td>\n",
       "      <td>0.835897</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.861579</td>\n",
       "      <td>0.971915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.257200</td>\n",
       "      <td>0.083818</td>\n",
       "      <td>0.886259</td>\n",
       "      <td>0.918882</td>\n",
       "      <td>0.902276</td>\n",
       "      <td>0.979492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.088002</td>\n",
       "      <td>0.896689</td>\n",
       "      <td>0.922972</td>\n",
       "      <td>0.909641</td>\n",
       "      <td>0.980575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1317, training_loss=0.1325849462116679, metrics={'train_runtime': 144.7877, 'train_samples_per_second': 72.727, 'train_steps_per_second': 9.096, 'total_flos': 233000610434676.0, 'train_loss': 0.1325849462116679, 'epoch': 3.0})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b77934-c1cf-4d71-b7e8-39168e0d6229",
   "metadata": {},
   "source": [
    "## Accelerated training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d007194-8501-4b43-9cc5-2ec6f7a67e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed087df3-04c0-4c8e-ba7c-c0a66e4fc5b5",
   "metadata": {},
   "source": [
    "### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0c33ad8-6a78-4de3-a357-708681824b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"].shuffle(seed=42).select(range(n_train_use)),\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"].shuffle(seed=42).select(range(n_eval_use)),\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "59f63a48-ddf6-4215-b6e5-381aaf3b97a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e316f3-5c51-43df-98e9-bb4cc9388654",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "73b13676-59a1-4ca1-be73-1d05ea44f6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Start fresh with our model\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2323d0f3-36ed-4c99-b5e4-7ef96956dd4e",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "54fa8222-bbaf-478e-ba5e-4111f8a9eaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7865b78a-8dc3-4ff3-8cb0-424bdad1f2d6",
   "metadata": {},
   "source": [
    "### Prepare with accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dd6c5bae-cef3-4b4d-8882-020acf241fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1d964e-af43-47ec-892b-490b08e98b4d",
   "metadata": {},
   "source": [
    "### Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f6187548-84c5-4529-900e-63c8688ebbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7a5cf0-e4db-406a-8405-149ddd30b9b1",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "49a1358d-0b60-4455-a614-0076ee74bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../temp/07/bert-finetuned-ner-accelerate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9602ea6-2f63-4428-aaf9-9dc1b51ea9e4",
   "metadata": {},
   "source": [
    "#### Define a post-processing function to simplify evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2b9407e4-4ec6-4fc1-931b-018263a63747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.detach().cpu().clone().numpy()\n",
    "    labels = labels.detach().cpu().clone().numpy()\n",
    "\n",
    "    true_labels, true_predictions = prepped_labels_and_preds(labels, predictions, label_names)\n",
    "    return true_labels, true_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64bdec5-1ffb-4611-ad45-f761ee1fc3a2",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2d34144a-954c-4083-810d-16054af5799f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c62a994b52948eb92cc5e8d8f3b21f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1317 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  {'precision': 0.8657123381049762, 'recall': 0.8089171974522293, 'f1': 0.8363516628251564, 'accuracy': 0.9657204714938658}\n",
      "Epoch 1:  {'precision': 0.901840490797546, 'recall': 0.8574206092028516, 'f1': 0.8790697674418604, 'accuracy': 0.9765455857589608}\n",
      "Epoch 2:  {'precision': 0.9120654396728016, 'recall': 0.8802631578947369, 'f1': 0.8958821560093739, 'accuracy': 0.9779889343276401}\n"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    \n",
    "    # Training block\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Evaluation block\n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        # Update padding to match (different processes might have different batch max lengths)\n",
    "        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
    "        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "\n",
    "        predictions_gathered = accelerator.gather(predictions)\n",
    "        labels_gathered = accelerator.gather(labels)\n",
    "\n",
    "        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "        metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    results = metric.compute()\n",
    "    print(\n",
    "        f\"Epoch {epoch}: \", {key: results[f\"overall_{key}\"] for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]}\n",
    "    )\n",
    "\n",
    "    # Save results\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27e4e0f-fcb2-4b72-b18d-e1cc87c8e213",
   "metadata": {},
   "source": [
    "# Estimation using the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b5388de9-c4f5-4f83-afd5-83f571d3d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_checkpoint = \"../temp/07/bert-finetuned-ner-accelerate/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b50d5896-992d-4a6b-9f2e-ff54e36875cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_classifier = pipeline(\n",
    "    \"token-classification\", model=local_model_checkpoint, aggregation_strategy=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3b7b32fa-1178-4544-b9eb-de24ee5fa7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9926579,\n",
       "  'word': 'Sylvain',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.85100394,\n",
       "  'word': 'Hu',\n",
       "  'start': 33,\n",
       "  'end': 35},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.4837528,\n",
       "  'word': '##gging',\n",
       "  'start': 35,\n",
       "  'end': 40},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.5974179,\n",
       "  'word': 'Face',\n",
       "  'start': 41,\n",
       "  'end': 45},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9922236,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154dc4a9-6855-4bcd-ae7c-8adbb590d7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
